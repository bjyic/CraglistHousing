{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "try:\n",
    "    from Queue import Queue  # PY2\n",
    "except ImportError:\n",
    "    from queue import Queue  # PY3\n",
    "from threading import Thread\n",
    "try:\n",
    "    from urlparse import urljoin  # PY2\n",
    "except ImportError:\n",
    "    from urllib.parse import urljoin  # PY3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from six import iteritems\n",
    "from six.moves import range\n",
    "\n",
    "sites_url = 'http://www.craigslist.org/about/sites'\n",
    "\n",
    "\n",
    "def get_all_sites():\n",
    "    response = requests.get(sites_url)\n",
    "    response.raise_for_status()  # Something failed?\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    sites = set()\n",
    "\n",
    "    for box in soup.findAll('div', {'class': 'box'}):\n",
    "        for a in box.findAll('a'):\n",
    "            # Remove protocol and get subdomain\n",
    "            site = a.attrs['href'].rsplit('//', 1)[1].split('.')[0]\n",
    "            sites.add(site)\n",
    "\n",
    "    return sites\n",
    "ALL_SITES = get_all_sites()  # All the Craiglist sites\n",
    "RESULTS_PER_REQUEST = 100  # Craigslist returns 100 results per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def requests_get(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Retries if a RequestException is raised (could be a connection error or\n",
    "    a timeout).\n",
    "    \"\"\"\n",
    "\n",
    "    logger = kwargs.pop('logger', None)\n",
    "    try:\n",
    "        return requests.get(*args, **kwargs)\n",
    "    except RequestException as exc:\n",
    "        if logger:\n",
    "            logger.warning('Request failed (%s). Retrying ...', exc)\n",
    "        return requests.get(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_list_filters(url):\n",
    "    list_filters = {}\n",
    "    response = requests_get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    for list_filter in soup.find_all('div', class_='search-attribute'):\n",
    "        filter_key = list_filter.attrs['data-attr']\n",
    "        filter_labels = list_filter.find_all('label')\n",
    "        options = [opt.text.strip() for opt in filter_labels]\n",
    "        list_filters[filter_key] = {'url_key': filter_key, 'value': options}\n",
    "    return list_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_futures.sessions import FuturesSession\n",
    "import re\n",
    "class CraigslistBase(object):\n",
    "    \"\"\" Base class for all Craiglist wrappers. \"\"\"\n",
    "\n",
    "    url_templates = {\n",
    "        'base': 'http://%(site)s.craigslist.org',\n",
    "        'no_area': 'http://%(site)s.craigslist.org/search/%(category)s',\n",
    "        'area': 'http://%(site)s.craigslist.org/search/%(area)s/%(category)s'\n",
    "    }\n",
    "\n",
    "    default_site = 'sfbay'\n",
    "    default_category = None\n",
    "\n",
    "    base_filters = {\n",
    "        'query': {'url_key': 'query', 'value': None},\n",
    "        'search_titles': {'url_key': 'srchType', 'value': 'T'},\n",
    "        'has_image': {'url_key': 'hasPic', 'value': 1},\n",
    "        'posted_today': {'url_key': 'postedToday', 'value': 1},\n",
    "        'search_distance': {'url_key': 'search_distance', 'value': None},\n",
    "        'zip_code': {'url_key': 'postal', 'value': None},\n",
    "    }\n",
    "    extra_filters = {}\n",
    "\n",
    "    # Set to True to subclass defines the customize_results() method\n",
    "    custom_result_fields = False\n",
    "\n",
    "    sort_by_options = {\n",
    "        'newest': 'date',\n",
    "        'price_asc': 'priceasc',\n",
    "        'price_desc': 'pricedsc',\n",
    "    }\n",
    "\n",
    "    def __init__(self, site=None, area=None, category=None, filters=None,\n",
    "                 log_level=logging.WARNING):\n",
    "        # Logging\n",
    "        self.set_logger(log_level, init=True)\n",
    "\n",
    "        self.site = site or self.default_site\n",
    "        if self.site not in ALL_SITES:\n",
    "            msg = \"'%s' is not a valid site\" % self.site\n",
    "            self.logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        if area:\n",
    "            if not self.is_valid_area(area):\n",
    "                msg = \"'%s' is not a valid area for site '%s'\" % (area, site)\n",
    "                self.logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "        self.area = area\n",
    "\n",
    "        self.category = category or self.default_category\n",
    "\n",
    "        url_template = self.url_templates['area' if area else 'no_area']\n",
    "        self.url = url_template % {'site': self.site, 'area': self.area,\n",
    "                                   'category': self.category}\n",
    "\n",
    "        list_filters = get_list_filters(self.url)\n",
    "\n",
    "        self.filters = {}\n",
    "        for key, value in iteritems((filters or {})):\n",
    "            try:\n",
    "                filter = (self.base_filters.get(key) or\n",
    "                          self.extra_filters.get(key) or\n",
    "                          list_filters[key])\n",
    "                if filter['value'] is None:\n",
    "                    self.filters[filter['url_key']] = value\n",
    "                elif isinstance(filter['value'], list):\n",
    "                    valid_options = filter['value']\n",
    "                    if not hasattr(value, '__iter__'):\n",
    "                        value = [value]  # Force to list\n",
    "                    options = []\n",
    "                    for opt in value:\n",
    "                        try:\n",
    "                            options.append(valid_options.index(opt) + 1)\n",
    "                        except ValueError:\n",
    "                            self.logger.warning(\n",
    "                                \"'%s' is not a valid option for %s\"\n",
    "                                % (opt, key)\n",
    "                            )\n",
    "                    self.filters[filter['url_key']] = options\n",
    "                elif value:  # Don't add filter if ...=False\n",
    "                    self.filters[filter['url_key']] = filter['value']\n",
    "            except KeyError:\n",
    "                self.logger.warning(\"'%s' is not a valid filter\", key)\n",
    "\n",
    "    def set_logger(self, log_level, init=False):\n",
    "        if init:\n",
    "            self.logger = logging.getLogger('python-craiglist')\n",
    "            self.handler = logging.StreamHandler()\n",
    "            self.logger.addHandler(self.handler)\n",
    "        self.logger.setLevel(log_level)\n",
    "        self.handler.setLevel(log_level)\n",
    "\n",
    "    def is_valid_area(self, area):\n",
    "        base_url = self.url_templates['base']\n",
    "        response = requests_get(base_url % {'site': self.site},\n",
    "                                logger=self.logger)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        sublinks = soup.find('ul', {'class': 'sublinks'})\n",
    "        return sublinks and sublinks.find('a', text=area) is not None\n",
    "\n",
    "    def get_results(self, limit=None, start=0, sort_by=None, geotagged=False):\n",
    "        \"\"\"\n",
    "        Get results from Craigslist based on the specified filters.\n",
    "        If geotagged=True, the results will include the (lat, lng) in the\n",
    "        'geotag' attrib (this will make the process a little bit longer).\n",
    "        \"\"\"\n",
    "\n",
    "        if sort_by:\n",
    "            try:\n",
    "                self.filters['sort'] = self.sort_by_options[sort_by]\n",
    "            except KeyError:\n",
    "                msg = (\"'%s' is not a valid sort_by option, \"\n",
    "                       \"use: 'newest', 'price_asc' or 'price_desc'\" % sort_by)\n",
    "                self.logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "        total_so_far = start\n",
    "        results_yielded = 0\n",
    "        total = 0\n",
    "\n",
    "        while True:\n",
    "            self.filters['s'] = start\n",
    "            response = requests_get(self.url, params=self.filters,\n",
    "                                    logger=self.logger)\n",
    "            self.logger.info('GET %s', response.url)\n",
    "            self.logger.info('Response code: %s', response.status_code)\n",
    "            response.raise_for_status()  # Something failed?\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            if not total:\n",
    "                totalcount = soup.find('span', {'class': 'totalcount'})\n",
    "                total = int(totalcount.text) if totalcount else 0\n",
    "\n",
    "            for row in soup.find_all('p', {'class': 'result-info'}):\n",
    "                if limit is not None and results_yielded >= limit:\n",
    "                    break\n",
    "                self.logger.debug('Processing %s of %s results ...',\n",
    "                                  total_so_far + 1, total)\n",
    "\n",
    "                link = row.find('a', {'class': 'hdrlnk'})\n",
    "                id = link.attrs['data-id']\n",
    "                name = link.text\n",
    "                url = urljoin(self.url, link.attrs['href'])\n",
    "\n",
    "                time = row.find('time')\n",
    "                if time:\n",
    "                    datetime = time.attrs['datetime']\n",
    "                else:\n",
    "                    pl = roprintw.find('span', {'class': 'pl'})\n",
    "                    datetime = pl.text.split(':')[0].strip() if pl else None\n",
    "                price = row.find('span', {'class': 'result-price'})\n",
    "                where = row.find('span', {'class': 'result-hood'})\n",
    "                if where:\n",
    "                    where = where.text.strip()[1:-1]  # remove ()\n",
    "                tags_span = row.find('span', {'class': 'result-tags'})\n",
    "                tags = tags_span.text if tags_span else ''\n",
    "\n",
    "                result = {#'id': id,\n",
    "                          'name': name,\n",
    "                          'url': url,\n",
    "                          'datetime': datetime,\n",
    "                          'price': price.text if price else None,\n",
    "                          'where': where,\n",
    "                          'has_image': 'pic' in tags#,\n",
    "                          # TODO: Look into this, looks like all show map now\n",
    "                          #'has_map': 'map' in tags,\n",
    "                #          'geotag': None\n",
    "                }\n",
    "                \n",
    "                session=FuturesSession()\n",
    "                future = session.get(url)\n",
    "                response_detail= future.result()\n",
    "                soup_response_detail=BeautifulSoup(response_detail.text,\"lxml\")\n",
    "                \n",
    "                try:\n",
    "                    mapaddress_pre=soup_response_detail.find_all(['div','p'], {'class': 'mapaddress'})\n",
    "                    mapaddress=''\n",
    "                    for i in mapaddress_pre:\n",
    "                        mapaddress=mapaddress+i.text.replace('\\n\\n','\\n')\n",
    "                    #mapaddress=mapaddress_pre[0].text.replace('\\n\\n','\\n')\n",
    "                    result.update({'mapaddress':mapaddress})\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    detail_content_pre=soup_response_detail.find_all(id='postingbody')\n",
    "                    detail_content=''\n",
    "                    for i in detail_content_pre:\n",
    "                        detail_content=detail_content+i.text.replace(unicode('\\n\\nQR Code Link to This Post\\n\\n\\n'),'')\\\n",
    "                        .replace('\\n\\n','\\n')\n",
    "\n",
    "                    #detail_content=detail_content_pre[0].text.replace(unicode('\\n\\nQR Code Link to This Post\\n\\n\\n'),'')\\\n",
    "                    #.replace('\\n\\n','\\n')\n",
    "                    result.update({'detail_content':detail_content})\n",
    "\n",
    "\n",
    "                    chinese_flag=re.findall(ur'[\\u4e00-\\u9fff]+', detail_content)\n",
    "\n",
    "\n",
    "                    if len(chinese_flag)>0:\n",
    "                        chinese_content=True\n",
    "                    else:\n",
    "                        chinese_content=False\n",
    "                    result.update({'chinese_content':chinese_content})\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    attrgroup_pre=soup_response_detail.find_all(['div','p'], {'class': 'attrgroup'})\n",
    "                    attr_text=''\n",
    "                    for tmp in attrgroup_pre:\n",
    "                        attr_text=attr_text+tmp.text.replace('\\n\\n','\\n')\n",
    "                    result.update({'attr_text':attr_text})\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                geolocation=geolocation=soup_response_detail.find_all(['div','p'], {'class': 'viewposting'})\n",
    "                try:\n",
    "                    geolocation=geolocation[0]\n",
    "                    geolocation_latitude=geolocation.attrs['data-latitude']\n",
    "                    geolocation_longitude=geolocation.attrs['data-longitude']\n",
    "                    result.update({'geolocation_latitude':geolocation_latitude})\n",
    "                    result.update({'geolocation_longitude':geolocation_longitude})\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                if self.custom_result_fields:\n",
    "                    self.customize_result(result, row)\n",
    "\n",
    "                if geotagged and result['has_map']:\n",
    "                    self.geotag_result(result)\n",
    "\n",
    "                yield result\n",
    "                results_yielded += 1\n",
    "                total_so_far += 1\n",
    "\n",
    "            if results_yielded == limit:\n",
    "                break\n",
    "            if (total_so_far - start) < RESULTS_PER_REQUEST:\n",
    "                break\n",
    "            start = total_so_far\n",
    "\n",
    "    def customize_result(self, result, html_row):\n",
    "        \"\"\" Add custom/delete/alter fields to result. \"\"\"\n",
    "        pass  # Override in subclass to add category-specific fields.\n",
    "\n",
    "    def geotag_result(self, result):\n",
    "        \"\"\" Adds (lat, lng) to result. \"\"\"\n",
    "\n",
    "        self.logger.debug('Geotagging result ...')\n",
    "\n",
    "        if result['has_map']:\n",
    "            response = requests_get(result['url'], logger=self.logger)\n",
    "            self.logger.info('GET %s', response.url)\n",
    "            self.logger.info('Response code: %s', response.status_code)\n",
    "\n",
    "            if response.ok:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                map = soup.find('div', {'id': 'map'})\n",
    "                if map:\n",
    "                    result['geotag'] = (float(map.attrs['data-latitude']),\n",
    "                                        float(map.attrs['data-longitude']))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def geotag_results(self, results, workers=8):\n",
    "        \"\"\"\n",
    "        Add (lat, lng) to each result. This process is done using N threads,\n",
    "        where N is the amount of workers defined (default: 8).\n",
    "        \"\"\"\n",
    "\n",
    "        results = list(results)\n",
    "        queue = Queue()\n",
    "\n",
    "        for result in results:\n",
    "            queue.put(result)\n",
    "\n",
    "        def geotagger():\n",
    "            while not queue.empty():\n",
    "                self.logger.debug('%s results left to geotag ...',\n",
    "                                  queue.qsize())\n",
    "                self.geotag_result(queue.get())\n",
    "                queue.task_done()\n",
    "\n",
    "        threads = []\n",
    "        for _ in range(workers):\n",
    "            thread = Thread(target=geotagger)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return results\n",
    "\n",
    "    @classmethod\n",
    "    def show_filters(cls, category=None):\n",
    "        print('Base filters:')\n",
    "        for key, options in iteritems(cls.base_filters):\n",
    "            value_as_str = '...' if options['value'] is None else 'True/False'\n",
    "            print('* %s = %s' % (key, value_as_str))\n",
    "        print('Section specific filters:')\n",
    "        for key, options in iteritems(cls.extra_filters):\n",
    "            value_as_str = '...' if options['value'] is None else 'True/False'\n",
    "            print('* %s = %s' % (key, value_as_str))\n",
    "        url = cls.url_templates['no_area'] % {\n",
    "            'site': cls.default_site,\n",
    "            'category': category or cls.default_category,\n",
    "        }\n",
    "        list_filters = get_list_filters(url)\n",
    "        for key, options in iteritems(list_filters):\n",
    "            value_as_str = ', '.join([repr(opt) for opt in options['value']])\n",
    "            print('* %s = %s' % (key, value_as_str))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CraigslistHousing(CraigslistBase):\n",
    "    \"\"\" Craigslist housing wrapper. \"\"\"\n",
    "\n",
    "    default_category = 'hhh'\n",
    "    custom_result_fields = True\n",
    "\n",
    "    extra_filters = {\n",
    "        'private_room': {'url_key': 'private_room', 'value': 1},\n",
    "        'private_bath': {'url_key': 'private_bath', 'value': 1},\n",
    "        'cats_ok': {'url_key': 'pets_cat', 'value': 1},\n",
    "        'dogs_ok': {'url_key': 'pets_dog', 'value': 1},\n",
    "        'min_price': {'url_key': 'min_price', 'value': None},\n",
    "        'max_price': {'url_key': 'max_price', 'value': None},\n",
    "        'min_ft2': {'url_key': 'minSqft', 'value': None},\n",
    "        'max_ft2': {'url_key': 'maxSqft', 'value': None},\n",
    "        'min_bedrooms': {'url_key': 'min_bedrooms', 'value': None},\n",
    "        'max_bedrooms': {'url_key': 'max_bedrooms', 'value': None},\n",
    "        'min_bathrooms': {'url_key': 'min_bathrooms', 'value': None},\n",
    "        'max_bathrooms': {'url_key': 'max_bathrooms', 'value': None},\n",
    "        'no_smoking': {'url_key': 'no_smoking', 'value': 1},\n",
    "        'is_furnished': {'url_key': 'is_furnished', 'value': 1},\n",
    "        'wheelchair_acccess': {'url_key': 'wheelchaccess', 'value': 1},\n",
    "    }\n",
    "\n",
    "    def customize_result(self, result, html_row):\n",
    "        housing_info = html_row.find('span', {'class': 'housing'})\n",
    "        # Default values\n",
    "        result.update({'bedrooms': None, 'area': None})\n",
    "        if housing_info:\n",
    "            for elem in housing_info.text.split('-'):\n",
    "                elem = elem.strip()\n",
    "                if elem.endswith('br'):\n",
    "                    # Don't convert to int, too risky\n",
    "                    result['bedrooms'] = elem[:-2]\n",
    "                if elem.endswith('2'):\n",
    "                    result['area'] = elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_h = CraigslistHousing(site='sfbay', area='sby', category='roo',\n",
    "                        # filters={'max_price': 2000, 'private_room': True}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apa=CraigslistHousing(site='sfbay', area='sby', category='apa',\n",
    "                     #    filters={'max_price': 2000, 'private_room': True}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>attr_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>chinese_content</th>\n",
       "      <th>datetime</th>\n",
       "      <th>detail_content</th>\n",
       "      <th>geolocation_latitude</th>\n",
       "      <th>geolocation_longitude</th>\n",
       "      <th>has_image</th>\n",
       "      <th>mapaddress</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150ft2</td>\n",
       "      <td>\\n150ft2\\navailable may 1\\n\\nw/d in unit\\nno smoking\\ncarport\\nprivate bath\\nprivate room\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-07-03 15:01</td>\n",
       "      <td>Nice, Large, Bright, room W/ Semi private Bath, Private entrance, Security, and Covered driveway parking Available for Rent.Room is 13 x 11.5 feet. Furnished or unfurnished. Amenities include: Swimming pool, Jacuzzi, Weight rooms, Sauna, Tennis court, Billiards room, Library, and Clubhouse. Wifi, cable, and all utilities included. \\nCentrally located for easy commute.\\nEasy access to Hwy 85/87/280/880/101 Etc.\\nMinutes away from local shopping &amp; restaurants.\\nClose to Monterey Rd. and Tully\\Curtner  (Fairgrounds)\\nWalking distance to VTA bus stop, Light Rail, and Cal Train, Shopping, and Restaurants.  Quiet &amp; safe neighborhood.\\n</td>\n",
       "      <td>37.294437</td>\n",
       "      <td>-121.852756</td>\n",
       "      <td>True</td>\n",
       "      <td>\\n        (google map)\\n        \\n</td>\n",
       "      <td>NICE, LARGE ROOM W/ SEMI PRIVATE BATH, PRIVATE ENTRANCE, SECURITY, AND</td>\n",
       "      <td>$1150</td>\n",
       "      <td>http://sfbay.craigslist.org/sby/roo/6179828056.html</td>\n",
       "      <td>san jose south</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  \\\n",
       "0  150ft2   \n",
       "\n",
       "                                                                                     attr_text  \\\n",
       "0  \\n150ft2\\navailable may 1\\n\\nw/d in unit\\nno smoking\\ncarport\\nprivate bath\\nprivate room\\n   \n",
       "\n",
       "  bedrooms  chinese_content          datetime  \\\n",
       "0  None     False            2017-07-03 15:01   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  detail_content  \\\n",
       "0  Nice, Large, Bright, room W/ Semi private Bath, Private entrance, Security, and Covered driveway parking Available for Rent.Room is 13 x 11.5 feet. Furnished or unfurnished. Amenities include: Swimming pool, Jacuzzi, Weight rooms, Sauna, Tennis court, Billiards room, Library, and Clubhouse. Wifi, cable, and all utilities included. \\nCentrally located for easy commute.\\nEasy access to Hwy 85/87/280/880/101 Etc.\\nMinutes away from local shopping & restaurants.\\nClose to Monterey Rd. and Tully\\Curtner  (Fairgrounds)\\nWalking distance to VTA bus stop, Light Rail, and Cal Train, Shopping, and Restaurants.  Quiet & safe neighborhood.\\n   \n",
       "\n",
       "  geolocation_latitude geolocation_longitude  has_image  \\\n",
       "0  37.294437            -121.852756           True        \n",
       "\n",
       "                           mapaddress  \\\n",
       "0  \\n        (google map)\\n        \\n   \n",
       "\n",
       "                                                                     name  \\\n",
       "0  NICE, LARGE ROOM W/ SEMI PRIVATE BATH, PRIVATE ENTRANCE, SECURITY, AND   \n",
       "\n",
       "   price                                                  url           where  \n",
       "0  $1150  http://sfbay.craigslist.org/sby/roo/6179828056.html  san jose south  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_colwidth',3)\n",
    "df = pd.DataFrame(cl_h.get_results(sort_by='newest', limit=1))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='sfbay.craigslist.org', port=80): Max retries exceeded with url: /sby/apa/6203234781.html (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000000D7F18D0>: Failed to establish a new connection: [Errno 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-97a1b0e36b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msort_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-dd947732b65c>\u001b[0m in \u001b[0;36mget_results\u001b[1;34m(self, limit, start, sort_by, geotagged)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFuturesSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[0mresponse_detail\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[0msoup_response_detail\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_detail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\concurrent\\futures\\_base.pyc\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\concurrent\\futures\\thread.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    516\u001b[0m         }\n\u001b[0;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cnyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\requests\\adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    500\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='sfbay.craigslist.org', port=80): Max retries exceeded with url: /sby/apa/6203234781.html (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000000D7F18D0>: Failed to establish a new connection: [Errno 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.DataFrame(apa.get_results(sort_by='newest'))\n",
    "df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
